import { NextRequest, NextResponse } from "next/server";
import { recordUsage } from "@/lib/metrics/usage";
import { analyzeContribution } from "@/features/analyze/analyzeContribution";
import { step_analyze_multi_llm } from "@/app/pipeline/steps/analyze_multi_llm";

export const runtime = "nodejs"; export const dynamic = "force-dynamic";

export async function POST(req: NextRequest){
  const t0 = Date.now();
  let ok=false, err:string|null=null, model:string|undefined, totalTokens:number|undefined;
  let out:any=null;
  try{
    const url = new URL(req.url);
    const mode = url.searchParams.get("mode") || (process.env.VOG_ANALYZE_MODE || "gpt");
    const body = await req.json().catch(()=>({}));
    const text = String((body as any)?.text ?? "").trim().slice(0, 8000);
    const maxClaims = Number((body as any)?.maxClaims ?? 3);
    if(!text){ out={ error:"Kein Text Ã¼bergeben.", status:400 }; ok=true; return NextResponse.json(out,{status:200}); }
    out = mode==="multi" ? await step_analyze_multi_llm(text,{maxClaims}) : await analyzeContribution(text,{maxClaims});
    model = out?._meta?.model || process.env.OPENAI_API_MODEL || undefined;
    totalTokens = out?._meta?.usage?.total_tokens || undefined;
    ok=true;
    return NextResponse.json(out,{status:200});
  }catch(e:any){
    err = String(e?.message||e);
    out = { _meta:{ mode:"error", errors:[String(err)], tookMs: Date.now()-t0 } };
    return NextResponse.json(out,{status:200});
  }finally{
    await recordUsage({ ts:Date.now(), route:"/api/contributions/analyze", userId:null, model:model||null,
      totalTokens: totalTokens||null, ms: Date.now()-t0, ok, err: ok?null:err, meta:{ source:"wrapper" } });
  }
}
